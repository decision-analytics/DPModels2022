{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/bigsem.png\" width=\"40%\" align=\"right\">\n",
    "<img src=\"img/logo_wiwi.png\" width=\"20%\" align=\"left\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "# Dynamic Programming Models in Combinatorial Optimization\n",
    "**Winter Term 2021/22**\n",
    "\n",
    "\n",
    "# 1. Introduction to Dynamic Programming (Models)\n",
    "\n",
    "<img src=\"img/decision_analytics_logo.png\" width=\"17%\" align=\"right\">\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**J-Prof. Dr. Michael RÃ¶mer |  Decision Analytics Group**\n",
    "                                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview\n",
    "- Combinatorial Optimization Problems and Greedy Algorithms\n",
    "- From Greedy to Dynamic Programming (Models)\n",
    "- Online Value Function Approximation\n",
    "- Wrapping up and Outlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combinatorial optimization problems\n",
    "\n",
    "- combinatorial optimization (CO) problems are discrete optimization problems, that is, optimization problems in which the set of feasible solutions is discrete\n",
    "- well-known examples for CO problems are\n",
    "  - the the travelling salesperson problem (TSP)\n",
    "  - the 0/1 knapsack problem\n",
    "  - the set covering problem\n",
    "- many CO problems are NP-hard, that is, there no known algorithm that can solve them in polynomial time\n",
    "- in this course, we will learn \n",
    "  - how (certain) CO problems can be cast as dynamic programming models\n",
    "  - and how such models can be useful for solving CO problems approximately or exactly\n",
    "  - in very different ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Greedy Approaches to Combinatorial Optimization Problems\n",
    "- given that exactly solving (large) CO problems is often not (practically) tractable, one often resorts to heuristic approaches that aim at\n",
    "  - finding high-quality solutions\n",
    "  - in an acceptable amount of time\n",
    "- one class of heuristic solutions that are usually *very* fast (but not alway yield high-quality solutions) are so-called **greedy algorithms**\n",
    "- greedy algorithms solve a CO problem by construction a solution step by step\n",
    "- in every step, a decision is made according to a **greedy criterion**:\n",
    "  - in general, in case of different feasible options, the one that is (locally) optimal with respect to the greedy criterion is taken\n",
    "   - example: the nearest neighbor algorithm for solving the TSP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: the 0/1 knapsack problem\n",
    "\n",
    "Given \n",
    "- a knapsack with a capacity $W$ \n",
    "- and a set of items, each with a weight $w_i$ and a value $p_i$\n",
    "- determine the the subset of the items to put in the knapsack such that\n",
    "  - the total value of the items in the knapsack is maximal and\n",
    "  - the total weight of the items in the knapsack does not exceed $W$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:**\n",
    "\n",
    "<img src=\"./img/greedy/07.png\" width=\"20%\" align=\"right\">\n",
    "\n",
    "Assume you are a thief and you are about to steal the three items depicted below from an appartment. However, your backpack can only fit 35 lbs. Which items should you take?\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./img/greedy/08.png\" width=\"40%\" align=\"left \">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Greedy Approach for the Knapsack Problem\n",
    "\n",
    "- start with some item: If it (still) fits in the backpack, put it in the backpack\n",
    "- repeat for the remaining items\n",
    "\n",
    "..you never take out an item once it has been packed in the knapsack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def greedy_knapsack(values, weights, capacity):\n",
    "    solution = [] # solution array\n",
    "    obj_val = 0 # accumulated objective\n",
    "    total_weight = 0 # accumulated weight\n",
    "    \n",
    "    for i, weight in enumerate(weights): \n",
    "        if total_weight + weight <= capacity: ## if the item still fits..\n",
    "            solution.append(i) ## add it and \n",
    "            total_weight+= weight # update the accumulated weight\n",
    "            obj_val += values[i] # as well as the optimal objective value\n",
    "    return obj_val, solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..let us try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, [0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [3000,2000,1500]\n",
    "weights = [30,20,15]\n",
    "capacity = 35\n",
    "\n",
    "greedy_knapsack(values, weights, capacity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let us try larger instances\n",
    "\n",
    "..there are many instance sets for the 0/1 KP\n",
    "- as an example, there are some instances from D. Pisinger, see the instances folder in the repository associated with this notebook\n",
    "- on the following website, you will find optimal objective function values:\n",
    "\n",
    "http://artemisa.unicauca.edu.co/~johnyortega/instances_01_KP/\n",
    "\n",
    ".. you find some instances in the GitHub repository in which this notebook resides\n",
    "- if you download the zip with this notebook (or clone the repository), you will have them in the folder `problems/knapsack/instances`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Format of the knapsack instances\n",
    "\n",
    "the instance files have the following format:\n",
    "\n",
    "- first row: `number_of_items` `capacity`\n",
    "- every further row contains informatin for each item: `value` `weight`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our toy instance would look like this:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "3 35\n",
    "3000 30\n",
    "2000 20\n",
    "1500 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading in the instances\n",
    "\n",
    "The following function reads an instance file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def read_knapsack_instance(filename):\n",
    "    weights=[]\n",
    "    values=[]\n",
    "    with open(filename) as f: # open the file\n",
    "        line = f.readline().split()  # split first row\n",
    "        number_of_items = int(line[0]) # read number of items\n",
    "        capacity = int(line[1]) # read capacity\n",
    "        for i in range(number_of_items): # read rows for the items\n",
    "            line = f.readline().split() # split row\n",
    "            values.append(int(line[0])) # read value\n",
    "            weights.append(int(line[1])) # read weight\n",
    "    return np.array(values), np.array(weights), capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "... let us try with a 5000-item instance and solve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33727"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"./../problems/knapsack/instances/knapPI_1_5000_1000_1\" # optimal value: 276457\n",
    "values, weights, capacity  = read_knapsack_instance(filename)\n",
    "\n",
    "obj_value, _ = greedy_knapsack(values, weights, capacity)\n",
    "obj_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise: Improving the greedy approach by sorting items\n",
    "\n",
    "- one way to improve the performance of this greedy algorithm for the knapsack problem is to sort items\n",
    "- which sorting criteria do you consider promising?\n",
    "- sort the items accordingly and try applying the greedy algorithm to the sorted items\n",
    "\n",
    "#### Hint:\n",
    "In numpy, there is the function `argsort` which does not return the sorted values of an array, but an array of the sorted sorted indexes!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Travelling Salesperson Problem\n",
    "\n",
    "<img src=\"https://pup-assets.imgix.net/onix/images/9780691163529.jpg\" width=\"20%\" align=\"right\">\n",
    "\n",
    "\n",
    "**Informal problem statement:** Given a set of cities and the distances between the cities, find a minimum-cost round-trip that visits each city exactly once.\n",
    "\n",
    "**More formally:** Given a complete graph and distances between each pair of nodes in the graph, find a cost-minimal hamiltonian cycle in the graph\n",
    "\n",
    "\n",
    "- one of the best-known combinatorial opimization problem \n",
    "- **A nice book on the TSP:**  [In Pursuit of the Traveling Salesman](https://press.princeton.edu/books/paperback/9780691163529/in-pursuit-of-the-traveling-salesman)\n",
    " - die story of the TSP presented by one of its protagonists (William Cook)\n",
    "- TSP website: https://www.math.uwaterloo.ca/tsp/index.html\n",
    "- there are a lot of instances\n",
    "    - in particular, there is a full library of instances, the so-called [TSPLib](http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/)\n",
    "    - some of them are part of the git repository for the course material\n",
    "    - [here](http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/STSP.html) you find optimal objective values for many instances\n",
    "\n",
    "**..and there is even a Python library dedicated to solving the TSP: [`python-tsp`](https://github.com/fillipe-gsm/python-tsp)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nearest Neighbor: A greedy algorithm for the TSP\n",
    "\n",
    "- we assume that the cities are indexed from 0 to $N-1$\n",
    "\n",
    "Goal: create a list forming a permutation of the city indexes representing a tour with a small total distance \n",
    "- start with some node and add it to the list\n",
    "- find a node that is not yet in the list and that is nearest to the most recently added node and add it to the list\n",
    "- repeat until the list has length $N$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A helper function that computes the nearest neighbor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_nearest_neighbor(distance_matrix, permutation):\n",
    "    \n",
    "    # node the last node in the permutation\n",
    "    node = permutation[len(permutation)-1]\n",
    "    \n",
    "    smallest_distance = 9999999999 ## some large value\n",
    "    nearest_neighbor = 0\n",
    "    \n",
    "    #number of nodes = dimension of the distance matrix\n",
    "    for neighbor in range(len(distance_matrix)):\n",
    "        \n",
    "        if neighbor in permutation: continue # skip if already visited\n",
    "        \n",
    "        #update the nearest neighbor if needed\n",
    "        if distance_matrix[node][neighbor] < smallest_distance: \n",
    "            nearest_neighbor = neighbor\n",
    "            smallest_distance = distance_matrix[node][neighbor]            \n",
    "       \n",
    "    return nearest_neighbor, smallest_distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The full algorithm in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def tsp_nearest_neighbor(distance_matrix, permutation):\n",
    "    \n",
    "    total_distance = 0\n",
    "    \n",
    "    #as long as the list is not \"full\"\n",
    "    while len(permutation) < len(distance_matrix):\n",
    "        \n",
    "        node, distance = get_nearest_neighbor(distance_matrix, permutation)\n",
    "        \n",
    "        permutation.append(node)\n",
    "        total_distance += distance\n",
    "        \n",
    "    total_distance += distance_matrix[permutation[len(permutation)-1], permutation[0]] # final\n",
    "    return permutation, total_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let us try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 2, 3, 1], 17)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix = np.array([\n",
    "    [0,  5, 4, 10],\n",
    "    [5,  0, 8,  5],\n",
    "    [4,  8, 0,  3],\n",
    "    [10, 5, 3,  0]\n",
    "])\n",
    "\n",
    "tsp_nearest_neighbor(distance_matrix, [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Python library `python-tsp`\n",
    "\n",
    "see: https://github.com/fillipe-gsm/python-tsp\n",
    "\n",
    "### offers:\n",
    "- functions to read TSP instances in the tsplib-format\n",
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30774"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from python_tsp.distances import tsplib_distance_matrix\n",
    "\n",
    "#tsplib_file = \"./../problems/tsp/instances/a280.tsp\" # optimal solution 2579 (lt. http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/STSP.html)\n",
    "tsplib_file = \"./../problems/tsp/instances/brazil58.tsp\" # optimal solution 25395 (lt. http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/STSP.html)\n",
    "#tsplib_file = \"./../problems/tsp/instances/berlin52.tsp\" # optimal solution  7542 (lt. http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/STSP.html)\n",
    "\n",
    "distance_matrix = tsplib_distance_matrix(tsplib_file)\n",
    "\n",
    "permutation, distance = tsp_nearest_neighbor(distance_matrix, [0])\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- and heuristic as well as exact TSP algorithms\n",
    "  - e.g. local search, simulated annealing and dynamic programming (exact: careful, may take very long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25810"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from python_tsp.heuristics import solve_tsp_local_search, solve_tsp_simulated_annealing\n",
    "\n",
    "#permutation, distance = solve_tsp_local_search(distance_matrix)\n",
    "\n",
    "permutation, distance = solve_tsp_simulated_annealing(distance_matrix)\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Improving nearest neighbor: multi-start\n",
    "\n",
    "- one way to improve a greedy heuristic such as nearest neighbor that relies parameters (here: start city) is to call the greedy algorithm multiple times with different parameters\n",
    "- in general, many greedy algorithms are so fast that calling them multiple times is a perfectly feasible approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Task: Write a function that calls the nearest-neighbor algorithm for every possible start node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def tsp_multi_start_nearest_neighbor(distance_matrix):\n",
    "\n",
    "    return permutation, total_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation, distance = tsp_multi_start_nearest_neighbor(distance_matrix)\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A generic wrapper function for calling a function solving the TSP\n",
    "- to simplify our further experiments let us write a function that can call any function solving a TSP\n",
    "- we use `*args` to allow passing arguments (e.g. start node) to the function\n",
    "- the wrapper function\n",
    "  - reads the distance matrix\n",
    "  - solves the problem\n",
    "  - checks the solution for feasibility\n",
    "  - prints instance name, function name, total distance and time spent for solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "instance_name = \"brazil58\"\n",
    "def solve_tsp_using_function(instance_name, tsp_function, *args):\n",
    "    tsplib_file = f\"./../problems/tsp/instances/{instance_name}.tsp\" \n",
    "    distance_matrix = tsplib_distance_matrix(tsplib_file)\n",
    "    starttime = timer()  \n",
    "    permutation, distance = tsp_function(distance_matrix, *args)\n",
    "    if set(permutation) != set(range(len(distance_matrix))):\n",
    "        print (\"Not a proper permutation!\")\n",
    "    \n",
    "    print(f\"{instance_name}, {tsp_function.__name__}, distance: {distance}, time: {timer()- starttime:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trying out our generic wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "..with a function from the TSPLib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brazil58, solve_tsp_simulated_annealing, distance: 25627, time: 4.981\n"
     ]
    }
   ],
   "source": [
    "solve_tsp_using_function(instance_name, solve_tsp_simulated_annealing)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "..with our nearest neigbor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brazil58, tsp_nearest_neighbor, distance: 30774, time: 0.005\n"
     ]
    }
   ],
   "source": [
    "solve_tsp_using_function(instance_name, tsp_nearest_neighbor, [0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "..and finally, with our multi-start function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "solve_tsp_using_function(instance_name, tsp_multi_start_nearest_neighbor, [0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Speeding up with numba\n",
    "\n",
    "**`numba`**\n",
    "\n",
    "-  among other things, numba allows to **just-in-time** compile Python code\n",
    "- this make Python code much faster\n",
    "- but it only applies to a certain subset of Python\n",
    "- see https://numba.pydata.org/ for more information\n",
    "\n",
    "- most simple approach to apply numba use the *decorators* `@njit` above the function to just-in-time compile\n",
    "- let us try this out with the function `tsp_multi_start_nearest_neighbor` and re-do the timing \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# From Greedy to Dynamic Programming (Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modeling a discrete multi-stage transition system\n",
    "\n",
    "<img src=\"./img/deterministic_multistage_problem.png\" width=\"60%\">\n",
    "\n",
    "\n",
    "\n",
    "- $k$ the current step / stage (e.g. the number of cities visited so far), out of $N$ stages.\n",
    "- $x_k$ the current state needed to calculate the next step and the cost\n",
    "    - e.g. the cities visited visited so far and the current city\n",
    "    - the start state is defined as $x_0$\n",
    "- $u_k$ a decision from the set $U_k(x_k)$ of feasible decisions when being in stage $k$ and in state $x_k$ \n",
    "  - e.g. a city that was not visited so far  \n",
    "- $g(x_k, u_k)$ the cost of choosing decision $u_k$ when being in state $x_k$\n",
    "  - e.g. the distance to the next city\n",
    "- $f(x_k, u_k)$ a transition function that computes $x_{k+1}$ from $x_k$ und the decision $u_k$ \n",
    "  - e.g. an augmentation of the cities visited so far and an update of the current city\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A dynamic programming model\n",
    "\n",
    "A model for such a discrete system as defined on the previous slide along with the optimization problem:\n",
    "\n",
    "$$\\min_{u_0,..,u_k,..u_{N-1}} \\sum_{k=0}^{N-1} g_k(x_k,u_k)$$\n",
    "\n",
    "\n",
    "..will be referred to as a **dynamic programming model** in this remainder of this course, and we will refer to this generic problem as $DP$ in what follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Observe:\n",
    "- here, we assume a minimization problem, but it is straightforward to obtain a corresponding maximization problem\n",
    "- we also assume the cost are \"stage-wise\"-additive (but: they can be state-dependent!)\n",
    "- we assume there are no terminal costs $g(x_N)$ (would be straightforward to include)\n",
    "- there can be far more general DP models, but for now we stick to classes that can be represented as displayed above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: A DP model for the Knapsack Problem\n",
    "\n",
    "Given:\n",
    "- a knapsack instance with $N$ items with weights $w_k$ and profits $p_k$ (zero-indexed) and capacity $W$ \n",
    "\n",
    "- state $x_k$: accumulated weight after adding the first $k-1$ items, $x_0 = 0$\n",
    "- decision $u_k \\in \\{0, 1\\}$ (0: do not add item $k$ to the knapsack; 1: add item $k$)\n",
    "- $U_k(x_k) = \\begin{cases} \n",
    "                \\{0,1\\} \\quad \\mathrm{if} \\quad x_k + w_k \\leq W \\\\\n",
    "                \\{0 \\} \\quad \\mathrm{else}\n",
    "\\end{cases}$\n",
    "- $f(x_k, u_k) = x_k + w_k u_k $\n",
    "- $g(x_k, u_k) = p_k u_k$\n",
    "\n",
    "We have a maximization-objective:\n",
    "\n",
    "$$\\max_{u_0,..,u_k,..u_{N-1}} \\sum_{k=0}^{N-1} g_k(x_k,u_k)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: A DP model for the TSP\n",
    "\n",
    "Given:\n",
    "- a TSP instance with a $N$ cities and distances $d_{i,j}$ between cities $i,j$\n",
    "  - let us denote with $\\mathcal{N} = \\{1, \\ldots N \\}$ the set of cities \n",
    "\n",
    "\n",
    "\n",
    "- state $x_k$: sequence / ordered set of cities visited so far, $x_0 = i^0$ where $i^0$ is the first city\n",
    "  - let us define $l(x_k)$ as the last element in the order set, that is, the \"current\" city\n",
    "\n",
    "- decision $u_k \\in \\{1, .. N\\}$ city to visit next \n",
    "- $U_k(x_k) = \\mathcal{N} \\setminus x_k$\n",
    "- $f(x_k, u_k) = x_k + u_k$  (here, with $+$ we mean to append $u_k$ to the sequence / ordered set $x_k$\n",
    "- $g(x_k, u_k) = \\begin{cases} \n",
    "                d_{l(x_k), u_k} \\quad \\mathrm{if} \\quad k < N-1 \\\\\n",
    "               d_{l(x_k), u_k} +  d_{u_k, i^0} \\quad  \\mathrm{if} \\quad k = N-1\n",
    "\\end{cases}$\n",
    "\n",
    "We have a minimization objective:\n",
    "\n",
    "$$\\min_{u_0,..,u_k,..u_{N-1}} \\sum_{k=0}^{N-1} g_k(x_k,u_k)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Greedy as a myopic policy \n",
    "\n",
    "- we will see later how to solve a $DP$ model to optimality\n",
    "\n",
    "- in general, we refer to a function $\\pi$ that maps a state $x_k$ to a decision $u_k$ as a **policy**\n",
    "- in a deterministic problem, given a policy $\\pi$, we can obtain a solution to $DP$ by \n",
    "  - starting from $x_k := x_0$ and selecting the $u_k$ according to the policy\n",
    "  - applying the state transition $x_{k+1} = f(x_k, u_k)$\n",
    "  - and continue until $k:= N -1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Greedy as a policy:\n",
    "- we can view the greedy algorithm as being based on a policy that selects a $u_k$ that minimizes the transition costs $g$:\n",
    "\n",
    "$$u_k = \\underset{u_k \\in U_k}{\\operatorname{argmin}} \\, g(x_k, u_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observe: This policy is **myopic** since it does not account for how deciding for a certain $u_k$ affects the quality of the remaining solution process - hence its name: *greedy*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accounting for the future: The value function \n",
    "\n",
    "\n",
    "- to quantify the future value (also called cost-to-go) of a state $x_k$, we use the so-called value function $J(x_k)$ \n",
    "  - given a state $x_k$, $J(x_k)$ represents the cost / value obtained by solving the residual problem from stages $k$ to $N-1$.\n",
    "  - the corresponding problem starting at $k$ is also referred to as the **tail subproblem**.\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " \n",
    "   \n",
    "Given a value function, we can compute the decision to take in stage  $k$ as:\n",
    "\n",
    "$$u_k = \\underset{u_k \\in U_k(x_k)}{\\operatorname{argmin}} \\, \\Big( g(x_k, u_k) + J(f(x_k, u_k)) \\Big) $$\n",
    "\n",
    "\n",
    "Observe that for the greedy policy for the knapsack, $J(x_{k}) = 0$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Q-values / Q-factors\n",
    "\n",
    "- in some cases, in particular in some reinforcement learning approaches, it is convenient to use so-called Q-factors,  Q-values or Q-functions\n",
    "\n",
    "$$Q_k(x_k, u_k) = g(x_k, u_k) + J\\big( f(x_k, u_k ) \\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "..using these Q-factors, we can re-write the problem of selecting the next decision / control / action as:\n",
    "\n",
    "$$u_k = \\underset{u_k \\in U_k(x_k)}{\\operatorname{argmin}} \\, Q_k(x_k, u_k) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimal and approximate value functions\n",
    "\n",
    "\n",
    "#### The optimal (exact) value function\n",
    "- we denote the exact / optimal value function with $J^*$.\n",
    "- if we have access to $J^*$, then the greedy policy based on $g(x_k, u_k) + J(f(x_k, u_k))$ gives us an optimal solution\n",
    "- the problem: $J^*$ is typically probitively hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Approximate value functions\n",
    "\n",
    "- we denote an approximate value function with $\\tilde{J}$\n",
    "- a greedy policy based on $\\tilde{J}$ is suboptimal,  but can be much faster to compute\n",
    "- approximate value functions can be determined in various ways $\\tilde{J}$:\n",
    "  - using offline training / learning\n",
    "  - using problem simplfication or aggregation (solve an approximate tail problem)\n",
    "  - using online techniquest (e.g. rollout), see later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exact Dynamic Programming\n",
    "\n",
    "How to obtain an exact value function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In general,  this requires exactly solving the DP model\n",
    "- there are various ways to do this (backward or forward), we will consider this in somewhat more detail next week\n",
    "- for large-scale COP, exactly solving the DP model usually takes probhibitively long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exact Dynamic Programming: An Illustration of the Knapsack Case\n",
    "\n",
    "One approach to exactly solve a DP model is to\n",
    "- create the state transition graph and\n",
    "- compute the shortest (longest) path in the graph\n",
    "\n",
    "\n",
    "<img src=\"./img/reaching_05.png\" width=\"60%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Approximate value functions / approximation in value space\n",
    "\n",
    "\n",
    "### How can we obtain an approximate value function?\n",
    "\n",
    "#### Offline value function approximation\n",
    "\n",
    "- training machine learning models using given solutions obtained from\n",
    "  - exact or heuristic solution approaches\n",
    "  - of \"self-generated solutions\" obtained using reinforcement learning methods\n",
    "\n",
    "\n",
    "#### Online value function approximation\n",
    "\n",
    "- instead of pre-training, one obtains $\\tilde{J}$ by heurstically solving the tail subproblem using\n",
    "  - so-called rollout with a base heuristic\n",
    "  - possibly combined with so-called multi-step lookahead\n",
    "- this is what we will discuss now.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Online approximation in value space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Online approximation in value space\n",
    "\n",
    "We will consider the following approaches now:\n",
    "- rollout with greedy as base heuristic\n",
    "- approximate one-step minimization: simplified rollout\n",
    "- two-step lookahead with rollout\n",
    "- multi-step lookahead with rollout \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Running case study: TSP\n",
    "- how much are we able to improve upon a simple (multi-start) nearest neighbor algorithm?\n",
    "- will we be able to \"beat\" Python-TSP?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rollout with a Base Heuristic\n",
    "\n",
    "- recall that given an approximate value function $\\tilde{J}$, we can construct a policy that takes the decision according to the best approximate $Q-$-value $\\tilde{Q}_k(x_k, u_k)$\n",
    "\n",
    "$$u_k = \\underset{u_k \\in U_k(x_k)}{\\operatorname{argmin}} \\, \\tilde{Q}_k(x_k, u_k) = \\underset{u_k \\in U_k(x_k)}{\\operatorname{argmin}} \\, \\Big( g(x_k, u_k) +  \\tilde{J}(f(x_k, u_k)) \\Big) $$\n",
    "  \n",
    "  \n",
    "- key idea of rollout:  run a (simple and fast) base heuristic on the tail subproblem starting from $x_{k+1} = f(x_k, u_k)$ to obtain a cost / value $H(f(x_k, u_k))$, and use that value as value function approximation:\n",
    "  - $\\tilde{J}(x_{k+1}) = H (x_{k+1})$\n",
    "\n",
    "\n",
    "<img src=\"./img/rollout_general.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "..we will illustrate this now for the TSP, using nearest neighbor as the base heuristic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rollout with a Base Heuristic for the TSP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rollout with a base heuristic for the TSP: getting the next city\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'njit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;129m@njit\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_next_city_rollout_nn\u001b[39m(distance_matrix, permutation):\n\u001b[0;32m      4\u001b[0m     node \u001b[38;5;241m=\u001b[39m permutation[\u001b[38;5;28mlen\u001b[39m(permutation)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \n\u001b[0;32m      5\u001b[0m     best_q_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000000\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'njit' is not defined"
     ]
    }
   ],
   "source": [
    "@njit\n",
    "def get_next_city_rollout_nn(distance_matrix, permutation):\n",
    "    \n",
    "    node = permutation[len(permutation)-1] \n",
    "    best_q_value = 1000000\n",
    "    best_node = node        \n",
    "    \n",
    "    # loop over all u_k\n",
    "    for next_node in range(len(distance_matrix)):        \n",
    "        if next_node in permutation: continue # skip if infeasible (not in U(x_k))       \n",
    "            \n",
    "        # compute x_k+1 = f(x,u)\n",
    "        state_next_stage = permutation + [next_node]        \n",
    "        # compute J-tilde(x_k+1) using nn as base heuristic (_, means we ignore the first return value)\n",
    "        _, nn_value = tsp_nearest_neighbor(distance_matrix, state_next_stage)\n",
    "        \n",
    "        # (approximate) q_value = g(x_k,u_k) + J-tilde\n",
    "        q_value = distance_matrix[node,next_node] + nn_value\n",
    "        if q_value < best_q_value:\n",
    "            best_node = next_node\n",
    "            best_q_value = q_value  \n",
    "   \n",
    "    return best_node, distance_matrix[node,best_node]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rollout with a base heuristic for the TSP: the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def tsp_rollout_nn(distance_matrix, permutation):\n",
    "        \n",
    "    total_distance = 0\n",
    "    \n",
    "    #while the solution is not complete\n",
    "    while len(permutation) < len(distance_matrix):    \n",
    "        \n",
    "        next_node, distance = get_next_city_rollout_nn(distance_matrix, permutation)\n",
    "        permutation.append(next_node)\n",
    "        total_distance += distance     \n",
    "        \n",
    "    total_distance += distance_matrix[permutation[len(permutation)-1],permutation[0]]\n",
    "    return permutation, total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#solve_tsp_using_function(instance_name, tsp_rollout_nn, [0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rollout: Some comments\n",
    "\n",
    "\n",
    "- applying rollout is always at least as good as running only the base heuristic\n",
    "  - (as long as certain very natural conditions are satisified)\n",
    "- the base heuristic is not restricted to greedy heuristics, but may also involve\n",
    "  - ML-based policie, e.g. policies resulting from applying a \"policy (neural) network\"\n",
    "  - multiple different base heuristics\n",
    "- given that our policy involves one \"exact\" step before running the rollout, we call this aproach one-step lookahead minimization with rollout\n",
    "- one-step lookahead minimization also works with other value function approximations (e.g. those obtained from offline training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Approximate one-step minimization: Simplified rollout\n",
    "\n",
    "\n",
    "- applying to every decision may take a lot of time\n",
    "- this will be even more true for multi-step lookahead\n",
    "\n",
    "\n",
    "- in order to speed up the solution process, we can approximate the minimization step by not considering every single $u_k \\in U_k(x_k)$ but only the \"most promising\"\n",
    "  - as an example, we can use the greedy criterion $g(x_k,u_k)$ as criterion for restricting the decisions to consider.\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simplified rollout: getting the next city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_next_city_simplified_rollout_nn(distance_matrix, permutation,  max_number_of_neighbors_rollout):\n",
    "    \n",
    "    node = permutation[len(permutation)-1] \n",
    "                                    \n",
    "    best_q_value = 1000000\n",
    "    best_node = node\n",
    "   \n",
    "    #sort neighors according to greedy criterion\n",
    "    sorted_neighbors = np.argsort(distance_matrix[node])    \n",
    "    number_of_neighbors_rollout = 0\n",
    "    \n",
    "    for next_node in sorted_neighbors:\n",
    "        if next_node in permutation: continue            \n",
    "        \n",
    "        number_of_neighbors_rollout += 1        \n",
    "        if number_of_neighbors_rollout > max_number_of_neighbors_rollout:\n",
    "            break     \n",
    "                                    \n",
    "        #from now on: same as in non-simplified rollout     \n",
    "        state_next_stage = permutation + [next_node]        \n",
    "        # compute J-tilde(x_k+1) using nn as base heuristic (_, means we ignore the first return value)\n",
    "        _, nn_value = tsp_nearest_neighbor(distance_matrix, state_next_stage)\n",
    "        \n",
    "        # (approximate) q_value = g(x_k,u_k) + J-tilde\n",
    "        q_value = distance_matrix[node,next_node] + nn_value\n",
    "        if q_value < best_q_value:\n",
    "            best_node = next_node\n",
    "            best_q_value = q_value  \n",
    "\n",
    "    return best_node, distance_matrix[node,best_node]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simplified rollout: the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def tsp_simplified_rollout_nn(distance_matrix, permutation):\n",
    "    \n",
    "    # please complete this function!\n",
    "    \n",
    "    return permutation, total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#solve_tsp_using_function(instance_name, tsp_simplified_rollout_nn, [0])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multi-step lookahead\n",
    "\n",
    "- in (exact) dynamic programming (by reaching), we (somewhat) construct a full state-transition graph\n",
    "- in rollout, in each iteration, only the first step is \"exact\", the rest of the graph is approximated\n",
    "- in multi-step lookahead, we partially expand the tree for (more than one stage) to have more \"exact\" steps before using a value function approximation for selection\n",
    "- below: multi-step lookahead with rollout for value function approximation\n",
    "\n",
    "<img src=\"./img/multistep_lookahead.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Very important:\n",
    "- at each step $k$, only a single $u_k$ is selected - all the computations of the $u_{k+1}$ are only performed to get a better $\\tilde{J}$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Two-Step lookahead with rollout: getting the next city\n",
    "\n",
    "- let us start with two-step lookahead\n",
    "- we will directly start with a simplified version\n",
    "- please fill the gap in the function below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_next_city_simplified_two_step_lookahead(distance_matrix, permutation, max_number_of_neighbors):\n",
    "    \n",
    "    node = permutation[-1] \n",
    "    best_q_value = 1000000\n",
    "    best_node = node\n",
    "    \n",
    "    # caution: we cannot do more lookahead than there are steps left\n",
    "    number_of_lookahead_steps = min(number_of_lookahead_steps, len(distance_matrix) - len(permutation))    \n",
    "    \n",
    "    ## everything below is code needed for iterating over the first feasible next cities \n",
    "    ## (see above)\n",
    "    sorted_neighbors = np.argsort(distance_matrix[node])\n",
    "    number_of_neighbors = 0\n",
    "    for next_node in sorted_neighbors:\n",
    "        if next_node in permutation: continue     \n",
    "        number_of_neighbors += 1\n",
    "        if number_of_neighbors > max_number_of_neighbors:\n",
    "            break                     \n",
    "            \n",
    "        \n",
    "        state_next_stage = permutation + [next_node]\n",
    "        \n",
    "        ## how do we obtain an approximate value function in this case?\n",
    "        \n",
    "        # PLEASE FILL the gap here\n",
    "\n",
    "        q_value = distance_matrix[node,next_node] + value\n",
    "        \n",
    "        if q_value < best_q_value:\n",
    "            best_node = next_node\n",
    "            best_q_value = q_value\n",
    "    \n",
    "   \n",
    "    return best_node, distance_matrix[node,best_node]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Two-Step lookahead with rollout: main function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def tsp_simplified_two_step_lookahead(distance_matrix, permutation, max_number_of_neighbors):\n",
    "    \n",
    "\n",
    "    total_distance = 0    \n",
    "    node = permutation[len(permutation)-1]\n",
    "    \n",
    "    while len(permutation) < len(distance_matrix):   \n",
    "        \n",
    "        #two-step lookahead only makes sense \n",
    "        if len(permutation) < len(distance_matrix) -1:\n",
    "            node, distance = get_next_city_simplified_two_step_lookahead(distance_matrix, permutation, max_number_of_neighbors)\n",
    "        else:\n",
    "            node, distance = get_next_city_simplified_rollout_nn(distance_matrix, permutation, max_number_of_neighbors)\n",
    "            \n",
    "        permutation.append(node)\n",
    "        total_distance += distance     \n",
    "    \n",
    "\n",
    "    \n",
    "    total_distance += distance_matrix[permutation[len(permutation)-1],permutation[0]]\n",
    "    return permutation, total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve_tsp_using_function(instance_name, tsp_simplified_two_step_lookahead, [0])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (Generic) multi-step lookahead\n",
    "\n",
    "..how can we generically implement a multi-step lookahead version of the `get_next_city..`-function?\n",
    "\n",
    "- please fill the gap in the function below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_next_city_simplified_multi_step_lookahead(distance_matrix, permutation, max_number_of_neighbors, number_of_lookahead_steps):\n",
    "    node = permutation[-1] \n",
    "    best_q_value = 1000000\n",
    "    best_node = node\n",
    "    \n",
    "    # caution: we cannot do more lookahead than there are steps left\n",
    "    number_of_lookahead_steps = min(number_of_lookahead_steps, len(distance_matrix) - len(permutation))    \n",
    "    \n",
    "    ## everything below is code needed for iterating over the first feasible next cities \n",
    "    ## (see above)\n",
    "    sorted_neighbors = np.argsort(distance_matrix[node])\n",
    "    number_of_neighbors = 0\n",
    "    for next_node in sorted_neighbors:\n",
    "        if next_node in permutation: continue     \n",
    "        number_of_neighbors += 1\n",
    "        if number_of_neighbors > max_number_of_neighbors:\n",
    "            break                     \n",
    "        \n",
    "        state_next_stage = permutation + [next_node]\n",
    "        \n",
    "        ## how do we obtain an approximate value function in this case?\n",
    "        ##PLEASE FILL the gap here\n",
    "        \n",
    "        q_value = distance_matrix[node,next_node] + value\n",
    "\n",
    "        if q_value < best_q_value:\n",
    "            best_node = next_node\n",
    "            best_q_value = q_value\n",
    "    \n",
    "   \n",
    "    return best_node, distance_matrix[node,best_node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generic multi-step lookahead: the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def tsp_simplified_multi_step_lookahead(distance_matrix, permutation, max_number_of_neighbors, number_of_lookahead_steps):\n",
    "    \n",
    "\n",
    "    total_distance = 0\n",
    "    \n",
    "    node = permutation[len(permutation)-1]   \n",
    "\n",
    "    while len(permutation) < len(distance_matrix):    \n",
    "        \n",
    "        node, distance = get_next_city_simplified_multi_step_lookahead(distance_matrix,\n",
    "                                                                      permutation,                                                                      \n",
    "                                                                      max_number_of_neighbors,\n",
    "                                                                      number_of_lookahead_steps)\n",
    "        permutation.append(node)\n",
    "        total_distance += distance     \n",
    "     \n",
    "    \n",
    "    total_distance += distance_matrix[permutation[len(permutation)-1],permutation[0]]\n",
    "    return permutation, total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "number_of_lookahead steps \n",
    "#solve_tsp_using_function(instance_name, tsp_simplified_multi_step_lookahead, [0], 2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrapping up and Outlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Approximation in policy space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- so far, we discussed approximation in value space (approximating the value function $J$)\n",
    "- we then always used a policy by doing one-step lookahead minimization using the approximate value function $\\tilde{J}$:\n",
    " \n",
    " $$u_k = \\underset{u_k \\in U_k}{\\operatorname{argmin}} \\, g(x_k, u_k) + \\tilde{J}(x_{k+1})$$\n",
    "\n",
    "- however, it is also possible approximate policies $\\pi$ that directly give us a decision (without that minimization):\n",
    "\n",
    "$$u_k = \\pi(x_k)$$\n",
    "\n",
    "As an example, such an approximate $\\pi$ can be obtained via offline training:\n",
    "- optimizing a parameterized policy function (e.g. a linear decision rule)\n",
    "- in case of discrete decisions: training / learning a classification model based on given policicies or by reinforcement learning (self-learning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Observe:** \n",
    "\n",
    "- a (learned) approximate policy can be used as a base policy for a rollout algorithm\n",
    "- an offline learned policy can often be substantially improved by including some lookahead and rollout steps (\"online play\" in games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simplified AlphaZero architecture as an example for a hybrid approach\n",
    "\n",
    "<img src=\"./img/alpha_zero_sketch.png\" width=\"60%\">\n",
    "\n",
    "- \"Position evaluator\" is a value function approximation\n",
    "- rollout is not fully performed but truncated; at the end of the rollout, an approximate value function is used to account for the future value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References / Going deeper\n",
    "\n",
    "<img src=\"./img/lessons_az.jpg\" width=\"20%\" align=\"right\">\n",
    "\n",
    "- much of the notation and most figures are taken from presentations and books from D. Bertsekas\n",
    "- Bertsekas has many books, his most recent one (see on the right) is available for free\n",
    "- he also has a couple of lectures and courses available online\n",
    "- you can find links to all his materials on his website https://www.mit.edu/~dimitrib/home.html\n",
    "  - in particular in the section http://web.mit.edu/dimitrib/www/RLbook.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusions and Outlook\n",
    "\n",
    "\n",
    "#### This week, we...\n",
    "- got used to the concept of a DP model and dynamic programming\n",
    "- learned how to use simple greedy heuristics to derive relatively powerful heuristic solutions approaches\n",
    "- maybe got a first or different perspective on the relation of DP and reinforcement learning\n",
    "\n",
    "#### Next week, we...\n",
    "- will have a closer look at exact approaches for solving DP models#\n",
    "- will discuss so-called Decision Diagrams which\n",
    "  - provide an exact tecnnique for reducing the state-transition graph of a DP model\n",
    "  - provide a generic mechanism for obtaining combinatorial relaxations from DP models\n",
    "  - and, building on that, allow constructing an interesting Branch-and-Bound scheme that does not rely on LP relaxations"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:audprojekt2022]",
   "language": "python",
   "name": "conda-env-audprojekt2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
